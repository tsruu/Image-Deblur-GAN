{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0TmXSUuYiZj",
        "outputId": "d287d03f-df6d-402a-8dfd-dc1c83f92490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAz2EbLKZvFV"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/gopro_deblur.zip -d /content/drive/MyDrive/gopro_deblur\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:34.698118Z",
          "iopub.status.busy": "2024-09-27T16:14:34.697826Z",
          "iopub.status.idle": "2024-09-27T16:14:39.734904Z",
          "shell.execute_reply": "2024-09-27T16:14:39.733901Z",
          "shell.execute_reply.started": "2024-09-27T16:14:34.698084Z"
        },
        "id": "8UF-RdvTYc2D",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import pathlib\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:39.737792Z",
          "iopub.status.busy": "2024-09-27T16:14:39.737008Z",
          "iopub.status.idle": "2024-09-27T16:14:40.043604Z",
          "shell.execute_reply": "2024-09-27T16:14:40.042762Z",
          "shell.execute_reply.started": "2024-09-27T16:14:39.737756Z"
        },
        "id": "3wow23OZYc2E",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "blur_paths = glob.glob('/content/drive/MyDrive/gopro_deblur/gopro_deblur/blur/images/*.png')\n",
        "sharp_paths = glob.glob('/content/drive/MyDrive/gopro_deblur/gopro_deblur/sharp/images/*.png')\n",
        "blur_list = list(blur_paths)\n",
        "sharp_list = list(sharp_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:40.045181Z",
          "iopub.status.busy": "2024-09-27T16:14:40.044805Z",
          "iopub.status.idle": "2024-09-27T16:14:40.052271Z",
          "shell.execute_reply": "2024-09-27T16:14:40.051285Z",
          "shell.execute_reply.started": "2024-09-27T16:14:40.045126Z"
        },
        "id": "VTP9UdwCYc2F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class GoproDataset(Dataset):\n",
        "    def __init__(self, blurred_image_paths, sharp_image_paths, transform = None):\n",
        "        self.blurred_image_paths = blurred_image_paths\n",
        "        self.sharp_image_paths = sharp_image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.blurred_image_paths)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        blurred_image = Image.open(self.blurred_image_paths[idx])\n",
        "        sharp_image = Image.open(self.sharp_image_paths[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            blurred_image = self.transform(blurred_image)\n",
        "            sharp_image = self.transform(sharp_image)\n",
        "        return blurred_image, sharp_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:40.055149Z",
          "iopub.status.busy": "2024-09-27T16:14:40.054732Z",
          "iopub.status.idle": "2024-09-27T16:14:40.062589Z",
          "shell.execute_reply": "2024-09-27T16:14:40.061650Z",
          "shell.execute_reply.started": "2024-09-27T16:14:40.055105Z"
        },
        "id": "J94J_VnbYc2F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((640, 360)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:40.063845Z",
          "iopub.status.busy": "2024-09-27T16:14:40.063578Z",
          "iopub.status.idle": "2024-09-27T16:14:40.095451Z",
          "shell.execute_reply": "2024-09-27T16:14:40.094632Z",
          "shell.execute_reply.started": "2024-09-27T16:14:40.063815Z"
        },
        "id": "aG6cZ7MNYc2F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "dataset = GoproDataset(blur_list,sharp_list, data_transform)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:40.097138Z",
          "iopub.status.busy": "2024-09-27T16:14:40.096555Z",
          "iopub.status.idle": "2024-09-27T16:14:40.108777Z",
          "shell.execute_reply": "2024-09-27T16:14:40.107782Z",
          "shell.execute_reply.started": "2024-09-27T16:14:40.097106Z"
        },
        "id": "2MpHkZOEYc2F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.Convbock = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace = True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.Convbock(x)\n",
        "\n",
        "class Contract(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.contract = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "        ConvBlock(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.contract(x)\n",
        "\n",
        "class Expand(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.conv = ConvBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x = torch.cat([x1,x2], dim=1)\n",
        "        return self.conv(x)\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "        nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.out(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:40.113325Z",
          "iopub.status.busy": "2024-09-27T16:14:40.112988Z",
          "iopub.status.idle": "2024-09-27T16:14:40.129179Z",
          "shell.execute_reply": "2024-09-27T16:14:40.128371Z",
          "shell.execute_reply.started": "2024-09-27T16:14:40.113287Z"
        },
        "id": "RHQUc2vjYc2G",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Unet_generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Unet_generator,self).__init__()\n",
        "\n",
        "        self.inc = (ConvBlock(3,64))\n",
        "        self.down1 = (Contract(64,128))\n",
        "        self.down2 = (Contract(128,256))\n",
        "        self.down3 = (Contract(256,512))\n",
        "        # self.down4 = (Contract(512,1024))\n",
        "\n",
        "        # self.up1 = (Expand(1024, 512))\n",
        "        self.up2 = (Expand(512, 256))\n",
        "        self.up3 = (Expand(256, 128))\n",
        "        self.up4 = (Expand(128, 64))\n",
        "        self.outc = (OutConv(64, 3))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        # x5 = self.down4(x4)\n",
        "        # x = self.up1(x5, x4)\n",
        "        x = self.up2(x4, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        out = self.outc(x)\n",
        "        return out\n",
        "\n",
        "    def use_checkpointing(self):\n",
        "        self.inc = torch.utils.checkpoint(self.inc)\n",
        "        self.down1 = torch.utils.checkpoint(self.down1)\n",
        "        self.down2 = torch.utils.checkpoint(self.down2)\n",
        "        self.down3 = torch.utils.checkpoint(self.down3)\n",
        "        # self.down4 = torch.utils.checkpoint(self.down4)\n",
        "        # self.up1 = torch.utils.checkpoint(self.up1)\n",
        "        self.up2 = torch.utils.checkpoint(self.up2)\n",
        "        self.up3 = torch.utils.checkpoint(self.up3)\n",
        "        self.up4 = torch.utils.checkpoint(self.up4)\n",
        "        self.outc = torch.utils.checkpoint(self.outc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:40.130711Z",
          "iopub.status.busy": "2024-09-27T16:14:40.130347Z",
          "iopub.status.idle": "2024-09-27T16:14:40.146944Z",
          "shell.execute_reply": "2024-09-27T16:14:40.146016Z",
          "shell.execute_reply.started": "2024-09-27T16:14:40.130672Z"
        },
        "id": "DdsR_HfwYc2G",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape, ndf, n_layers=3, use_sigmoid=False):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        layers = [nn.Conv2d(in_channels=input_shape[0], out_channels=ndf, kernel_size=4, stride=2, padding=1)]\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        nf_mult, nf_mult_prev = 1, 1\n",
        "        for n in range(n_layers):\n",
        "            nf_mult_prev, nf_mult = nf_mult, min(2**n, 8)\n",
        "            layers.append(nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=4, stride=2, padding=1))\n",
        "            layers.append(nn.BatchNorm2d(ndf * nf_mult))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        nf_mult_prev, nf_mult = nf_mult, min(2**n_layers, 8)\n",
        "        layers.append(nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=4, stride=1, padding=1))\n",
        "        layers.append(nn.BatchNorm2d(ndf * nf_mult))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        layers.append(nn.Conv2d(ndf * nf_mult, 1, kernel_size=4, stride=1, padding=1))\n",
        "\n",
        "        if use_sigmoid:\n",
        "            layers.append(nn.Sigmoid())\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "        self.feature_size = self._get_conv_output(input_shape)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.feature_size, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 1)\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "\n",
        "        x = torch.rand(1, *shape)\n",
        "        x = self.model(x)\n",
        "        return int(torch.prod(torch.tensor(x.shape)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:40.148781Z",
          "iopub.status.busy": "2024-09-27T16:14:40.148109Z",
          "iopub.status.idle": "2024-09-27T16:14:40.899284Z",
          "shell.execute_reply": "2024-09-27T16:14:40.898280Z",
          "shell.execute_reply.started": "2024-09-27T16:14:40.148735Z"
        },
        "id": "bSGY5tN2Yc2G",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "netG = Unet_generator()\n",
        "netD = Discriminator((3,640,360),64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:40.902196Z",
          "iopub.status.busy": "2024-09-27T16:14:40.901779Z",
          "iopub.status.idle": "2024-09-27T16:14:41.140938Z",
          "shell.execute_reply": "2024-09-27T16:14:41.140161Z",
          "shell.execute_reply.started": "2024-09-27T16:14:40.902150Z"
        },
        "id": "QKkAHOQPYc2H",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "criterion_L1 = nn.L1Loss()\n",
        "\n",
        "optimizer_D = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_G = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "netG = netG.to(device)\n",
        "netD = netD.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:49.962502Z",
          "iopub.status.busy": "2024-09-27T16:14:49.962127Z",
          "iopub.status.idle": "2024-09-27T16:14:49.973152Z",
          "shell.execute_reply": "2024-09-27T16:14:49.971660Z",
          "shell.execute_reply.started": "2024-09-27T16:14:49.962454Z"
        },
        "id": "pke0FUb1Yc2H",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(dataloader, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (blurred_images, sharp_images) in enumerate(train_dataloader):\n",
        "            blurred_images = blurred_images.to(device)\n",
        "            sharp_images = sharp_images.to(device)\n",
        "\n",
        "            real_labels = torch.ones((blurred_images.size(0)), dtype=torch.float, device=device)\n",
        "            fake_labels = torch.zeros((blurred_images.size(0)), dtype=torch.float, device=device)\n",
        "\n",
        "            netD.zero_grad()\n",
        "\n",
        "    \n",
        "            output_real = netD(sharp_images).view(-1)\n",
        "            loss_real = criterion(output_real, real_labels)\n",
        "\n",
        "            \n",
        "            fake_images = netG(blurred_images)\n",
        "            output_fake = netD(fake_images.detach()).view(-1)\n",
        "\n",
        "            loss_fake = criterion(output_fake, fake_labels)\n",
        "\n",
        "            # Total Discriminator loss\n",
        "            loss_D = (loss_real + loss_fake) / 2\n",
        "            loss_D.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            #### Train Generator ####\n",
        "            netG.zero_grad()\n",
        "\n",
        "            # GAN loss (adversarial loss)\n",
        "            output_fake_for_G = netD(fake_images).view(-1)\n",
        "            loss_G_GAN = criterion(output_fake_for_G, real_labels)\n",
        "\n",
        "            # L1 Loss for pixel-wise image similarity\n",
        "            loss_G_L1 = criterion_L1(fake_images, sharp_images) * 100  # Weighted L1 loss\n",
        "\n",
        "            # Total Generator loss\n",
        "            loss_G = loss_G_GAN + loss_G_L1\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            fake_images.detach()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Epoch [{epoch}/{num_epochs}] | Batch [{i}/{len(dataloader)}] | Loss D: {loss_D.item()} | Loss G: {loss_G.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-27T16:14:51.396192Z",
          "iopub.status.busy": "2024-09-27T16:14:51.395816Z",
          "iopub.status.idle": "2024-09-27T16:14:55.853623Z",
          "shell.execute_reply": "2024-09-27T16:14:55.852031Z",
          "shell.execute_reply.started": "2024-09-27T16:14:51.396153Z"
        },
        "id": "jfnWEtr0Yc2H",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train(train_dataloader, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9BMEMLm8fcK4"
      },
      "outputs": [],
      "source": [
        "for i, (blurred_images, sharp_images) in enumerate(test_dataloader):\n",
        "\n",
        "    blurred_images = blurred_images.to(device)\n",
        "    sharp_images = sharp_images.to(device)\n",
        "\n",
        "    with torch.no_grad():  \n",
        "        output_images = netG(blurred_images)\n",
        "\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "a6VlTChczwzZ"
      },
      "outputs": [],
      "source": [
        "def denormalize(tensor):\n",
        "    tensor = tensor * 0.5 + 0.5  # Reverses the normalization step \n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlySOndwzLi9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "blurred_img = denormalize(blurred_images[0].cpu())\n",
        "output_img = denormalize(output_images[0].cpu())\n",
        "sharp_img = denormalize(sharp_images[0].cpu())\n",
        "\n",
        "blurred_img = transforms.ToPILImage()(blurred_img)\n",
        "output_img = transforms.ToPILImage()(output_img)\n",
        "sharp_img = transforms.ToPILImage()(sharp_img)\n",
        "\n",
        "# Display the images\n",
        "display(blurred_img)\n",
        "display(output_img)\n",
        "display(sharp_img)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 627736,
          "sourceId": 1118216,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30776,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
